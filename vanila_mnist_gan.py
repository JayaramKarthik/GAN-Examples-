# -*- coding: utf-8 -*-
"""vanila-mnist-gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IJie6hdY05nvL4EhAQ0ReSSwE7He0vj9
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torch.optim as optim
import numpy as np
import matplotlib

from torchvision.utils import make_grid , save_image
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from tqdm import tqdm

matplotlib.style.use('ggplot')

# learning parameters

batch_size = 128
epochs = 200
sample_size = 64 # fixed sample size
nz = 128 # latent vector size
k = 1 # number of steps to apply to the discriminator
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

transform = transforms.Compose([
                                transforms.ToTensor(),
                                transforms.Normalize((0.5,),(0.5,)),
])

to_pil_image = transforms.ToPILImage()

train_data = datasets.MNIST(
      root='.',
      train=True,
      download=True,
      transform = transform,
)
train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)

class Generator(nn.Module):
  def __init__(self,nz):
    super().__init__()
    self.nz = nz
    self.main = nn.Sequential(
        nn.Linear(self.nz,256),
        nn.LeakyReLU(0.2),

        nn.Linear(256,512),
        nn.LeakyReLU(0.2),

        nn.Linear(512,1024),
        nn.LeakyReLU(0.2),

        nn.Linear(1024,784),
        nn.Tanh(),
    )

  def forward(self,x):
    return self.main(x).view(-1,1,28,28)

class Discriminator(nn.Module):
  def __init__(self):
    super().__init__()
    self.n_input = 784
    self.main = nn.Sequential(
        nn.Linear(self.n_input,1024),
        nn.LeakyReLU(0.2),
        nn.Dropout(0.3),

        nn.Linear(1024,512),
        nn.LeakyReLU(0.2),
        nn.Dropout(0.3),

        nn.Linear(512,256),
        nn.LeakyReLU(0.2),
        nn.Dropout(0.3),

        nn.Linear(256,1),
        nn.Sigmoid(),
    )

  def forward(self,x):
    x = x.view(-1,784)
    return self.main(x)

generator = Generator(nz).to(device)
discriminator = Discriminator().to(device)

print('##### GENERATOR #####')
print(generator)
print('######################')
print('\n##### DISCRIMINATOR #####')
print(discriminator)
print('######################')

#optimizers
optim_g = optim.Adam(generator.parameters(),lr=0.0002)
optim_d = optim.Adam(discriminator.parameters(),lr=0.0002)

#loss function
loss_fn = nn.BCELoss()

losses_g = [] # to store generator loss after epoch
losses_d = [] # to store discriminator loss after each epoch
images = [] # to store images generated by the generator

# to create real labels (ls)
def label_real(size):
  data = torch.ones(size)
  return data.to(device)

# to create fake labels (0s)
def label_fake(size):
  data = torch.zeros(size)
  return data.to(device)

# function to create noise 
def create_noise(sample_size,nz):
  return torch.randn(sample_size,nz).to(device)

# save the images generated by the generator
def save_generator_image(image,path):
  save_image(image,path)

# function to train the discriminator network
def train_discriminator(optimizer,data_real,data_fake):
  b_size = data_real.size(0)
  real_label = label_real(b_size)
  fake_label = label_fake(b_size)

  optimizer.zero_grad()

  output_real = discriminator(data_real)
  loss_real = loss_fn(output_real,real_label)

  output_fake = discriminator(data_fake)
  loss_fake = loss_fn(output_fake,fake_label)

  loss_real.backward()
  loss_fake.backward()
  optimizer.step()

  return loss_real + loss_fake

#function to train generator network

def train_generator(optimizer,data_fake):
  b_size = data_fake.size(0)
  real_label = label_real(b_size)

  optimizer.zero_grad()

  output = discriminator(data_fake)
  loss = loss_fn(output,real_label)

  loss.backward()
  optimizer.step()

  return loss

#create the noise vector
noise = create_noise(sample_size,nz)
generator.train()
discriminator.train()

for epoch in range(epochs):
  loss_g = 0.0
  loss_d = 0.0
  for bi , data in tqdm(enumerate(train_loader),total=int(len(train_data)/batch_size)):
    image , _ = data
    image = image.to(device)
    b_size = len(image)
    #run discriminator k steps
    for step in range(k):
      data_fake = generator(create_noise(b_size,nz)).detach()
      data_real = image
      #train the discriminator network
      loss_d += train_discriminator(optim_d,data_real,data_fake)
  
    data_fake = generator(create_noise(b_size,nz))
    loss_g += train_generator(optim_g,data_fake)
  #create the final fake image for the epoch
  generated_img = generator(noise).cpu().detach()
  #make images as grid
  generated_img = make_grid(generated_img)
  epoch_loss_g = loss_g/bi
  epoch_loss_d = loss_d/bi
  losses_g.append(epoch_loss_g)
  losses_d.append(epoch_loss_d)

  if epoch % 10 == 0 :
    save_generator_image(generated_img,'./images/gen_img{}.png'.format(epoch))

  print("Epoch {} of {} ".format(epoch,epochs))
  print(" Generator Loss : {:.8f} , Discriminator Loss : {:.8f} ".format(epoch_loss_g,epoch_loss_d))

print('DONE TRAINING')
torch.save(generator.state_dict(), 'generator.pth')

# plot and save the generator and discriminator loss
plt.figure()
plt.plot(losses_g, label='Generator loss')
plt.plot(losses_d, label='Discriminator Loss')
plt.legend()
plt.savefig('loss.png')

